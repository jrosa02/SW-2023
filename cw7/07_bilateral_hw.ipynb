{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Filtracja Non-Local Means\n",
    "\n",
    "## Definicja\n",
    "\n",
    "Kolejny \"poziom wtajemniczenia\" w zagadnienie filtracji obrazów to metoda Non-Local Means (NLM).\n",
    "Została ona zaproponowana w pracy *\"A non-local algorithm for image denoising\"* (autorzy: Antoni Buades, Bartomeu Coll i Jean Michel Morel) na konferencji CVPR w 2005 roku.\n",
    "\n",
    "Filtr NLM dany jest zależnością:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{I}(\\mathbf{x}) = \\sum_{\\mathbf{p} \\in V(\\mathbf{x})} w(\\mathbf{p},\\mathbf{x})I(\\mathbf{p})\n",
    "\\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "gdzie:\n",
    "- $I$ - obraz wejściowy,\n",
    "- $\\hat{I}$ - obraz wyjściowy (przefiltrowany),\n",
    "- $\\mathbf{x}$ - współrzędne piksela obrazu,\n",
    "- $V(\\mathbf{x})$ - obszar poszukiwań piksela, dla którego przeprowadzana jest filtracja,\n",
    "- $w$ - waga punktu $\\mathbf{p}$ z obszaru poszukiwań.\n",
    "\n",
    "Wróćmy na chwilę do filtracji bilateralnej. Tam waga danego piksela z kontekstu zależała od dwóch czynników - odległości przestrzennej pomiędzy pikselami oraz różnicy w jasności/kolorze pomiędzy pikselami (tzw. przeciwdziedzina).\n",
    "Filtr NLM stanowi uogólnienie tej metody - do obliczania wag nie wykorzystuje się już pojedynczych pikseli ($\\mathbf{p}$ i $\\mathbf{x}$), a lokalne konteksty ($N(\\mathbf{p})$ i $N(\\mathbf{x})$).\n",
    "\n",
    "Waga $w$ dana jest następującą zależnością:\n",
    "\n",
    "\\begin{equation}\n",
    "w(\\mathbf{p},\\mathbf{x}) = \\frac{1}{Z(\\mathbf{x})}\\exp(-\\frac{|| v(N(\\mathbf{p})) - v(N(\\mathbf{x})) ||^2_{2}}{\\alpha \\sigma^2})\n",
    "\\tag{2}\n",
    "\\end{equation}\n",
    "\n",
    "gdzie:\n",
    "\\begin{equation}\n",
    "Z(\\mathbf{x}) = \\sum_{\\mathbf{p} \\in V(\\mathbf{x})} \\exp(-\\frac{|| v(N(\\mathbf{p})) - v(N(\\mathbf{x})) ||^2_{2}}{\\alpha \\sigma^2})\n",
    "\\tag{3}\n",
    "\\end{equation}\n",
    "\n",
    "- $|| \\cdot ||$ - jest normą $L_2$ odległości pomiędzy dwoma kontekstami,\n",
    "- $v$ oznacza mnożenie punktowe kontekstu $N$ przez dwuwymiarową maskę Gaussa o odpowiadających kontekstowi wymiarach,\n",
    "- $\\alpha$ > 0 - parametr sterujący filtracją,\n",
    "- $\\sigma$ - parametr szumu stacjonarnego występującego na obrazie (w przypadku szumu niestacjonarnego, parametr $\\sigma$ musi zostać dopasowany lokalnie tj. $\\sigma = \\sigma(\\mathbf{x})$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Analiza działania\n",
    "\n",
    "Zastanówmy sie teraz jak działa filtra NLM. Najprościej to zrozumieć na rysunku.\n",
    "\n",
    "![Ilustracja NLM](https://raw.githubusercontent.com/vision-agh/poc_sw/master/07_Bilateral/nlm.png)\n",
    "\n",
    "1. Dla rozważanego piksela $\\mathbf{x}$ definiujemy obszar poszukiwań $V(\\mathbf{x})$. Uwaga - obszar poszukiwań ($V$) jest jednostką większą niż otocznie/kontekst ($N$).\n",
    "\n",
    "2. Następnie, dla każdego z pikseli $\\mathbf{p} \\in  V(\\mathbf{x})$ oraz samego $\\mathbf{x}$ definiujemy otocznie/kontekst odpowiednio $N(\\mathbf{p})$ i $N(\\mathbf{x})$.\n",
    "\n",
    "3. Wracamy do równania definiującego wagę  $w(\\mathbf{p},\\mathbf{x})$, a konkretnie do wyrażenia $|| v(N(\\mathbf{p})) - v(N(\\mathbf{x})) ||$. Przeanalizujmy co ono oznacza. Mamy dwa otoczenia: $N(\\mathbf{p})$ i $N(\\mathbf{x})$. Każde z nich mnożymy przez odpowiadającą maskę Gaussa - funkcja $v$. Otrzymujemy dwie macierze, które odejmujemy od siebie punktowo. Następnie obliczamy kwadrat z normy ($L_2$ definiujemy jako $||X||_2 = \\sqrt{\\sum_k|X_k|^2}$. Otrzymujemy zatem jedną liczbę, która opisuje nam podobieństwo otoczeń pikseli $\\mathbf{x}$ i $\\mathbf{p}$. Mała wartość oznacza otoczenia zbliżone, duża - różniące się. Ponieważ, z dokładnością do stałych, liczba ta stanowi wykładnik funkcji $e^{-x}$, to ostatecznie waga jest zbliżona do 1 dla otoczeń podobnych, a szybko maleje wraz z malejącym podobieństwem kontekstów.\n",
    "\n",
    "4. Podsumowując: jak wynika z powyższej analizy filtr NLM to taki filtr bilateralny, w którym zamiast pojedynczych pikseli porównuje się ich lokalne otoczenia. Wpływa to pozytywnie na jakość filtracji, niestety kosztem złożoności obliczeniowej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Implementacja\n",
    "\n",
    "W ramach zadania należy zaimplementować filtr NLM, ocenić jego działanie w porównaniu do filtra Gaussa i bilateralnego oraz dokonać pomiaru czasu obliczeń (dla trzech wymienionych metod).\n",
    "\n",
    "Jak już się zrozumie jak działa NLM, jego implementacja jest dość prosta.\n",
    "Wartość parametru $\\alpha$ należy dobrać eksperymentalnie.\n",
    "Nie należy także \"przesadzić\" z rozmiarem obszaru poszukiwań (np. 11x11) oraz kontekstu (5x5 lub 3x3).\n",
    "\n",
    "Wskazówki do implementacji:\n",
    "- algorytm sprowadza się do dwóch podwójnych pętli for: zewnętrzne po pikselach, wewnętrzne po kolejnych obszarach przeszukań,\n",
    "- przed realizacją trzeba przemyśleć problem pikseli brzegowych - de facto problemów jest kilka. Po pierwsze nie dla każdego piksela można wyznaczyć pełny obszar przeszukań (tu propozycja, aby filtrację przeprowadzać tylko dla pikseli z pełnym obszarem). Po drugie, ponieważ rozpatrujemy konteksty, to nawet dla piksela o \"pełnym\" obszarze przeszukań, będą istnieć piksele, dla których nie pełnych kontekstów (sugestia - powiększyć obszar przeszukać, tak aby zawierał konteksty). Ostatni problem jest bardziej techniczny/implementacyjny. Jeśli w kolejnych iteracjach \"jawnie\" wytniemy fragment o rozmiarach obszaru przeszukiwań, to znowu pojawi się problem brzegowy - tu można albo wyciąć nieco większy obszar, albo cały czas \"pracować\" na obrazie oryginalnym (\"żonglerka indeksami\").\n",
    "- warto sprawdzać indeksy i rozmiary \"wycinanych\" kontekstów,\n",
    "- wagi wyliczamy w trzech krokach:\n",
    "    - obliczenia dla $N(\\mathbf{x})$ + inicjalizacja macierzy na wagi,\n",
    "    - podwójna pętla, w której przeprowadzamy obliczenia dla kolejnych $N(\\mathbf{p})$ oraz wyliczamy wagi,\n",
    "    - normalizacja macierzy wag oraz końcowa filtracja obszaru w wykorzystaniem wag.\n",
    "- uwaga, obliczenia trochę trwają, nawet dla obrazka 256x256 i względnie niewielkich obszaru przeszukań i kontesktu.\n",
    "\n",
    "Efekt końcowy:\n",
    "- porównanie wyników metod: filtr Gaussa, filtr bilateralny oraz filtr NLM (2-3 zdania komentarza),\n",
    "- porównanie czasu działania powyższych metod (1 zdanie komentarza).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import math\n",
    "import os\n",
    "import copy\n",
    "\n",
    "if not os.path.exists(\"MR_data.mat\") :\n",
    "    !wget https://raw.githubusercontent.com/vision-agh/poc_sw/master/07_Bilateral/MR_data.mat --no-check-certificate\n",
    "mr_data = loadmat('MR_data.mat')\n",
    "plt.gray()\n",
    "\n",
    "def fgaussian(size, sigma):\n",
    "     m = n = size\n",
    "     h, k = m//2, n//2\n",
    "     x, y = np.mgrid[-h:h+1, -k:k+1]\n",
    "     g = np.exp(-(x**2 + y**2)/(2*sigma**2))\n",
    "     return g /g.sum() \n",
    "       \n",
    "def mesh(fun, size):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "    X = np.arange(-size//2, size//2, 1)\n",
    "    Y = np.arange(-size//2, size//2, 1)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    Z = fun\n",
    "    ax.plot_surface(X, Y, Z)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def bilard(src: np.ndarray, delta) -> float:\n",
    "    gamma = src.copy().astype('float')\n",
    "    for j in range(src.shape[0]):\n",
    "        for i in range(src.shape[1]):\n",
    "            diff = src[src.shape[0]//2, src.shape[1]//2].astype('float') - src[j, i].astype('float')\n",
    "            gamma[j, i] = np.exp(-(diff**2)/(2*delta**2))\n",
    "    gamma = gamma/np.sum(gamma)\n",
    "    for j in range(src.shape[0]):\n",
    "        for i in range(src.shape[1]):\n",
    "            if gamma[j, i] < 1e-40:\n",
    "                gamma[j, i] = 0\n",
    "    return gamma\n",
    "\n",
    "def konvolucja_bil(srcc, size, sigma, delta):\n",
    "    src = srcc.astype('float')\n",
    "    fig, ax = plt.subplots(1, 3)\n",
    "    fig.set_size_inches(17, 8)\n",
    "    ax[0].imshow(src)\n",
    "    ax[0].set_title(\"Org\")\n",
    "    gauss_filter = fgaussian(size, sigma)\n",
    "    copsrc = src.copy().astype('float')\n",
    "    for row in range(size//2+1, copsrc.shape[0]-size//2-1):\n",
    "        for col in  range(size//2+1, copsrc.shape[1]-size//2-1):\n",
    "            kontext = src[row-size//2-1:row+size//2, col-size//2-1:col+size//2 ]\n",
    "            gamma = bilard(kontext, delta)\n",
    "            adaptive_filter = np.multiply(gamma, gauss_filter)\n",
    "            adaptive_filter = adaptive_filter/np.sum(adaptive_filter)\n",
    "            copsrc[row][col] = np.sum(np.multiply(kontext, adaptive_filter))\n",
    "            # if col == 110 and row == 70:\n",
    "            #     print(gamma)\n",
    "            #     print(kontext)\n",
    "            #     print(adaptive_filter)\n",
    "            #     print(copsrc[row, col])\n",
    "            #     plt.imshow(kontext)\n",
    "    ax[1].imshow(copsrc)\n",
    "    ax[1].set_title(\"Refined\")\n",
    "    ax[2].imshow(np.abs(np.subtract(src, copsrc)))\n",
    "    return copsrc\n",
    "\n",
    "def fgaussian(size, sigma):\n",
    "     m = n = size\n",
    "     h, k = m//2, n//2\n",
    "     x, y = np.mgrid[-h:h+1, -k:k+1]\n",
    "     g = np.exp(-(x**2 + y**2)/(2*sigma**2))\n",
    "     return g /g.sum() \n",
    "       \n",
    "def mesh(fun, size):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "    X = np.arange(-size//2, size//2, 1)\n",
    "    Y = np.arange(-size//2, size//2, 1)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    Z = fun\n",
    "    ax.plot_surface(X, Y, Z)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def konvolucja(src, size, sigma):\n",
    "    fig, ax = plt.subplots(1, 3)\n",
    "    fig.set_size_inches(16, 6)\n",
    "    ax[0].imshow(src)\n",
    "    ax[0].set_title(\"Org\")\n",
    "    gauss_filter = fgaussian(size, sigma)\n",
    "    #mesh(gauss_filter, size)\n",
    "    copsrc = src.copy()\n",
    "    for row in range(size//2+1, copsrc.shape[0]-size//2-1):\n",
    "        for col in  range(size//2+1, copsrc.shape[1]-size//2-1):\n",
    "            kontext = src[row-size//2-1:row+size//2, col-size//2-1:col+size//2 ]\n",
    "            copsrc[row][col] = np.sum(np.multiply(gauss_filter, kontext))\n",
    "    ax[1].imshow(copsrc)\n",
    "    ax[1].set_title(\"Refined\")\n",
    "    ax[2].imshow(np.abs(np.subtract(src, copsrc)))\n",
    "    return copsrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normscale = lambda diff, delta: np.exp(-(diff**2)/(2*delta**2))\n",
    "\n",
    "def new_pixel(V: np.ndarray, N_size, N_x, mask, delta) -> float:\n",
    "    weights = np.zeros(V.shape)\n",
    "    for row in range(N_size//2+1, V.shape[0]-N_size//2-1):\n",
    "        for col in  range(N_size//2+1, V.shape[1]-N_size//2-1):\n",
    "            N = V[row-N_size//2-1:row+N_size//2, col-N_size//2-1:col+N_size//2]\n",
    "            N = np.multiply(N, mask)\n",
    "            weights[row, col] = np.linalg.norm(N - N_x)\n",
    "            weights[row, col] = normscale(weights[row, col], delta)\n",
    "    weights = weights/np.sum(weights)\n",
    "    return np.sum(np.multiply(weights, V))\n",
    "    \n",
    "\n",
    "def NLM(srcc, V_size, N_size, sigma, delta):\n",
    "    src = srcc.astype('float')\n",
    "    copsrc = src.copy().astype('float')\n",
    "    mask = fgaussian(N_size, sigma)\n",
    "\n",
    "    for row in range(V_size//2+1, copsrc.shape[0]-V_size//2-1):\n",
    "        for col in  range(V_size//2+1, copsrc.shape[1]-V_size//2-1):\n",
    "\n",
    "            V = src[row-V_size//2-1:row+V_size//2, col-V_size//2-1:col+V_size//2]\n",
    "            N_x = src[row-N_size//2-1:row+N_size//2, col-N_size//2-1:col+N_size//2]\n",
    "            N_x = np.multiply(N_x, mask)\n",
    "\n",
    "            copsrc[row, col] = new_pixel(V, N_size, N_x, mask, delta)\n",
    "    return copsrc\n",
    "\n",
    "\n",
    "def imshow_NLM(src, transformed):\n",
    "    fig, ax = plt.subplots(1, 3)\n",
    "    fig.set_size_inches(17, 8)\n",
    "    ax[0].imshow(src)\n",
    "    ax[0].set_title(\"Org\")\n",
    "    ax[1].imshow(transformed)\n",
    "    ax[1].set_title(\"Refined\")\n",
    "    ax[2].imshow(np.abs(np.subtract(src, transformed)))\n",
    "    ax[2].set_title(\"Difference\")\n",
    "\n",
    "\n",
    "%timeit -n 1 -r 1 -o x = NLM(mr_data['I_noisy1'], 9, 3, 3, 3)\n",
    "%timeit -n 1 -r 1 -o imshow_NLM(mr_data['I_noisy1'], x)\n",
    "%timeit -n 1 -r 1 -o x = konvolucja_bil(mr_data['I_noisy1'], 9, 4, 4)\n",
    "%timeit -n 1 -r 1 -o x = konvolucja(mr_data['I_noisy1'], 7, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#najlepsze efekty daje transformacja NLM potem bilateralna a najbardziej rozmyte gausaa, NLM i gaus najlepeij pozbyły się szumów a bilateralny średnio.\n",
    "#Teoretycznie największą złożoność czasową ma algorytm NLM ale musiałem coś nieoptymalnie zaimplementować i algorytm bilateralny jest najwolniejszy, \n",
    "# bezpsprzecznie najszybszy jest algorytm konwolucji gaussa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
